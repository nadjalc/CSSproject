{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "import six\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('HMXPC13_DI_v2_5-14-14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['roles', 'incomplete_flag' , 'registered', 'certified'], axis=1) #We are dropping 3 columns:\n",
    "#registered becasue it has only value 1 and nothing else; \n",
    "#incoplete flag and roles because they have mostly Null values and are only used for administration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641138, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the begining of data cleaning we had 641138 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are checking 4 columnes- nevents, ndays_act, nplay_video and nchapters because we want to be sure they have NaN values for the state of no interaction that we can safely replace with the value zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0          63565\n",
       " 2.0          34329\n",
       " 3.0          17669\n",
       " 4.0          12217\n",
       " 5.0           9850\n",
       " 6.0           8480\n",
       " 7.0           7259\n",
       " 8.0           6648\n",
       " 9.0           6076\n",
       " 10.0          5621\n",
       " 11.0          5197\n",
       " 12.0          4870\n",
       " 13.0          4476\n",
       " 14.0          4222\n",
       " 15.0          3891\n",
       " 16.0          3808\n",
       " 17.0          3545\n",
       " 18.0          3349\n",
       " 19.0          3144\n",
       " 20.0          3064\n",
       " 21.0          2956\n",
       " 22.0          2795\n",
       " 23.0          2578\n",
       " 24.0          2621\n",
       " 25.0          2420\n",
       " 26.0          2391\n",
       " 27.0          2216\n",
       " 28.0          2170\n",
       " 29.0          2122\n",
       " 30.0          2079\n",
       "              ...  \n",
       " 30659.0          1\n",
       " 30810.0          1\n",
       " 30849.0          1\n",
       " 31396.0          1\n",
       " 31416.0          1\n",
       " 31761.0          1\n",
       " 31868.0          1\n",
       " 31900.0          1\n",
       " 31904.0          1\n",
       " 31943.0          1\n",
       " 32296.0          1\n",
       " 32498.0          1\n",
       " 32528.0          1\n",
       " 32812.0          1\n",
       " 33650.0          1\n",
       " 33661.0          1\n",
       " 33820.0          1\n",
       " 36244.0          1\n",
       " 37440.0          1\n",
       " 38065.0          1\n",
       " 41423.0          1\n",
       " 41895.0          1\n",
       " 43880.0          1\n",
       " 45201.0          1\n",
       " 45660.0          1\n",
       " 50032.0          1\n",
       " 53180.0          1\n",
       " 61376.0          1\n",
       " 197757.0         1\n",
       "NaN          199151\n",
       "Name: nevents, Length: 10610, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nevents'].value_counts(dropna = False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0      209941\n",
       " 2.0       80625\n",
       " 3.0       43081\n",
       " 4.0       26813\n",
       " 5.0       18552\n",
       " 6.0       13239\n",
       " 7.0       10281\n",
       " 8.0        8075\n",
       " 9.0        6510\n",
       " 10.0       5324\n",
       " 11.0       4415\n",
       " 12.0       3815\n",
       " 13.0       3323\n",
       " 14.0       2794\n",
       " 15.0       2542\n",
       " 16.0       2146\n",
       " 17.0       2002\n",
       " 18.0       1852\n",
       " 19.0       1564\n",
       " 20.0       1497\n",
       " 21.0       1339\n",
       " 22.0       1309\n",
       " 23.0       1207\n",
       " 24.0       1093\n",
       " 25.0       1027\n",
       " 26.0        947\n",
       " 27.0        887\n",
       " 28.0        891\n",
       " 29.0        838\n",
       " 30.0        806\n",
       "           ...  \n",
       " 131.0         4\n",
       " 132.0         4\n",
       " 133.0         4\n",
       " 134.0         3\n",
       " 135.0         2\n",
       " 136.0         5\n",
       " 137.0         1\n",
       " 138.0         4\n",
       " 139.0         1\n",
       " 140.0         1\n",
       " 141.0         4\n",
       " 142.0         2\n",
       " 143.0         4\n",
       " 144.0         1\n",
       " 147.0         3\n",
       " 148.0         1\n",
       " 149.0         1\n",
       " 150.0         1\n",
       " 151.0         1\n",
       " 153.0         1\n",
       " 155.0         3\n",
       " 157.0         1\n",
       " 158.0         1\n",
       " 159.0         2\n",
       " 160.0         1\n",
       " 162.0         1\n",
       " 165.0         1\n",
       " 176.0         1\n",
       " 205.0         1\n",
       "NaN       162743\n",
       "Name: ndays_act, Length: 160, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ndays_act'].value_counts(dropna = False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0         16968\n",
       " 2.0         11000\n",
       " 3.0          8371\n",
       " 4.0          6995\n",
       " 5.0          5992\n",
       " 6.0          5373\n",
       " 7.0          4714\n",
       " 8.0          4296\n",
       " 9.0          4076\n",
       " 10.0         3620\n",
       " 11.0         3453\n",
       " 12.0         3187\n",
       " 13.0         2853\n",
       " 14.0         2641\n",
       " 15.0         2453\n",
       " 16.0         2401\n",
       " 17.0         2138\n",
       " 18.0         2085\n",
       " 19.0         1887\n",
       " 20.0         1835\n",
       " 21.0         1803\n",
       " 22.0         1671\n",
       " 23.0         1565\n",
       " 24.0         1501\n",
       " 25.0         1553\n",
       " 26.0         1412\n",
       " 27.0         1330\n",
       " 28.0         1219\n",
       " 29.0         1179\n",
       " 30.0         1205\n",
       "             ...  \n",
       " 8012.0          1\n",
       " 8049.0          1\n",
       " 8052.0          1\n",
       " 8160.0          1\n",
       " 8223.0          1\n",
       " 8277.0          1\n",
       " 8469.0          1\n",
       " 8632.0          1\n",
       " 8727.0          1\n",
       " 9209.0          1\n",
       " 9310.0          1\n",
       " 9409.0          1\n",
       " 9473.0          1\n",
       " 9478.0          1\n",
       " 9509.0          1\n",
       " 9652.0          1\n",
       " 9754.0          1\n",
       " 9838.0          1\n",
       " 10668.0         1\n",
       " 11458.0         1\n",
       " 11491.0         1\n",
       " 12983.0         1\n",
       " 14523.0         1\n",
       " 15487.0         1\n",
       " 17314.0         1\n",
       " 19179.0         1\n",
       " 24564.0         1\n",
       " 34596.0         1\n",
       " 98517.0         1\n",
       "NaN         457530\n",
       "Name: nplay_video, Length: 2729, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nplay_video'].value_counts(dropna = False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0     121837\n",
       " 2.0     110085\n",
       " 3.0      52296\n",
       " 4.0      24937\n",
       " 5.0      13838\n",
       " 6.0       8536\n",
       " 7.0       6556\n",
       " 8.0       5009\n",
       " 9.0       4091\n",
       " 10.0      3598\n",
       " 11.0      3258\n",
       " 12.0      7987\n",
       " 13.0      2053\n",
       " 14.0      2021\n",
       " 15.0      2684\n",
       " 16.0      2890\n",
       " 17.0      1877\n",
       " 18.0      3411\n",
       " 19.0       473\n",
       " 20.0       624\n",
       " 21.0       424\n",
       " 22.0       150\n",
       " 23.0       149\n",
       " 24.0       157\n",
       " 25.0       250\n",
       " 26.0       339\n",
       " 27.0       352\n",
       " 28.0       193\n",
       " 29.0       179\n",
       " 30.0       181\n",
       " 31.0       385\n",
       " 32.0       657\n",
       " 33.0       511\n",
       " 34.0       271\n",
       " 35.0        16\n",
       " 36.0        23\n",
       " 37.0        15\n",
       " 38.0         8\n",
       " 39.0        10\n",
       " 40.0        12\n",
       " 41.0         5\n",
       " 42.0        11\n",
       " 43.0         6\n",
       " 44.0         3\n",
       " 45.0         3\n",
       " 46.0         3\n",
       " 47.0         5\n",
       " 48.0         6\n",
       "NaN      258753\n",
       "Name: nchapters, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['nchapters'].value_counts(dropna = False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering that all 4 tested columns have no value 0 we will now assign 0 to all rows that have NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['nevents'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['ndays_act'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['nplay_video'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['nchapters'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Country of origin data using get_dummies function - Converts categorical variable into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data['final_cc_cname_DI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive column Total Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the date is missing from the column \"last_event_DI\" this means that there was no interaction with the course after enrolment. Considering this we have decided to put starting date as the date of last interaction instead of NaN value. This way we keep all entries and we get 0 days active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"last_event_DI\"] = data.apply(lambda x: x.start_time_DI if pd.isnull(x.last_event_DI) else x.last_event_DI, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have checked the type of all dates entered in columnes \"start_time_DI\" and \"last_event_DI\" and they are all String. The code that we used is removed as it takes longer time to run.\n",
    "#### We now make a derivative columne that shows \"total_activity\" and it is determined from start time of the course and last event\n",
    "To work with dates, we need to convert them from strings into a data format built for processing dates. The pandas library comes with a Timestamp data object for storing and working with dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"start_time_DI\"] = pd.to_datetime(data[\"start_time_DI\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"last_event_DI\"] = pd.to_datetime(data[\"last_event_DI\"] ) #transfering dates so we can substract them to get days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['total_activity'] = data['last_event_DI'] - data['start_time_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['total_activity'] = data['total_activity'].apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data['YoB'].fillna(int(data['YoB'].mean()), inplace = True) #for missing values we set mean of all ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with NaN values and converting Level of education from categorical variable into indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['LoE_DI'] = data['LoE_DI'].fillna('UnknownLoE') #for missing values we assigned Unknown level of Education this is not\n",
    "# so high precentage of data as shown in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bachelor's             219768\n",
       "Secondary              169694\n",
       "Master's               118189\n",
       "UnknownLoE             106008\n",
       "Less than Secondary     14092\n",
       "Doctorate               13387\n",
       "Name: LoE_DI, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LoE_DI'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data['LoE_DI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with NaN values and converting Gender from categorical variable into indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['gender'].fillna('u', inplace = True) #changing NaN values to 'u' -unknown, again this is not too high precentage of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m    411520\n",
       "f    142795\n",
       "u     86806\n",
       "o        17\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(pd.get_dummies(data['gender']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some grades are empty string (space) and we drop those rows because we can work only with rows that have a grade as indicator of success on course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.loc[data['grade'] != \" \",] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True) #We drop all rows that have NaN after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Year of birth so we can derive column Age\n",
    "Based on multiple runs of code and investigations of data we reached a conclusion that columns that have a missing value for year of birth also have missing values for most of other columns like gender and level of education. After trying different options of assigning values and checking results we can say that the best result is when we dont fill in these values but just drop all rows with missing year of birth. From remaining rows we derive column \"age\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['age'] = data['YoB'].apply(lambda x: now.year - int(x)) # we use provided year of birth to calculate\n",
    "#age of all participants and save it as new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['grade'] = data['grade'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['course_id', 'userid_DI', 'viewed', 'explored', 'final_cc_cname_DI',\n",
       "       'LoE_DI', 'YoB', 'gender', 'grade', 'start_time_DI', 'last_event_DI',\n",
       "       'nevents', 'ndays_act', 'nplay_video', 'nchapters', 'nforum_posts',\n",
       "       'Australia', 'Bangladesh', 'Brazil', 'Canada', 'China', 'Colombia',\n",
       "       'Egypt', 'France', 'Germany', 'Greece', 'India', 'Indonesia', 'Japan',\n",
       "       'Mexico', 'Morocco', 'Nigeria', 'Other Africa', 'Other East Asia',\n",
       "       'Other Europe', 'Other Middle East/Central Asia',\n",
       "       'Other North & Central Amer., Caribbean', 'Other Oceania',\n",
       "       'Other South America', 'Other South Asia', 'Pakistan', 'Philippines',\n",
       "       'Poland', 'Portugal', 'Russian Federation', 'Spain', 'Ukraine',\n",
       "       'United Kingdom', 'United States', 'Unknown/Other', 'total_activity',\n",
       "       'Bachelor's', 'Doctorate', 'Less than Secondary', 'Master's',\n",
       "       'Secondary', 'UnknownLoE', 'f', 'm', 'o', 'u', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m    370685\n",
       "f    124105\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At the end of data cleaning we have 494790 rows which is around 77% of the begining dataset size. Because the number of rows is still significant and most of removed rows had a lot of missing information we consider this a good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
